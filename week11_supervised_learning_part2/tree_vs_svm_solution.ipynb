{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d451d01d",
   "metadata": {},
   "source": [
    "# ðŸ§ª Decision Tree vs SVM: Nonlinear Boundary Exploration\n",
    "This notebook explores how decision trees (axis-aligned) and support vector machines (nonlinear kernel) behave on different datasets.\n",
    "You will:\n",
    "- Visualize model boundaries\n",
    "- Tune hyperparameters\n",
    "- Compare model behavior\n",
    "- Think critically about non-linear decision surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb178970",
   "metadata": {},
   "source": [
    "## ðŸ”¢ 1. Load and visualize the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]\n",
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01081145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, X, y, ax, title):\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAAAFF'])\n",
    "    cmap_bold = ['#FF0000', '#0000FF']\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap=cmap_light, alpha=0.6)\n",
    "    for i, color in zip(np.unique(y), cmap_bold):\n",
    "        idx = np.where(y == i)\n",
    "        ax.scatter(X[idx, 0], X[idx, 1], c=color, label=f\"Class {i}\", edgecolor='k', s=30)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d632eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "tree.fit(X_scaled, y)\n",
    "svm = SVC(kernel='rbf', C=1)\n",
    "svm.fit(X_scaled, y)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_decision_boundary(tree, X_scaled, y, axes[0], \"Decision Tree (Iris)\")\n",
    "plot_decision_boundary(svm, X_scaled, y, axes[1], \"SVM (RBF Kernel, Iris)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d4cce",
   "metadata": {},
   "source": [
    "## ðŸŒ™ 2. make_moons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80b864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X_moon, y_moon = make_moons(n_samples=300, noise=0.2, random_state=42)\n",
    "X_moon_scaled = StandardScaler().fit_transform(X_moon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea81ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_moon = DecisionTreeClassifier(max_depth=4)\n",
    "tree_moon.fit(X_moon_scaled, y_moon)\n",
    "svm_moon = SVC(kernel='rbf', C=1)\n",
    "svm_moon.fit(X_moon_scaled, y_moon)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_decision_boundary(tree_moon, X_moon_scaled, y_moon, axes[0], \"Decision Tree (moons)\")\n",
    "plot_decision_boundary(svm_moon, X_moon_scaled, y_moon, axes[1], \"SVM (RBF Kernel, moons)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20890bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different parameters\n",
    "tree = DecisionTreeClassifier(max_depth=1).fit(X_moon_scaled, y_moon)\n",
    "svm = SVC(kernel='linear', C=0.1).fit(X_moon_scaled, y_moon)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_decision_boundary(tree, X_moon_scaled, y_moon, axes[0], \"Tree (depth=1)\")\n",
    "plot_decision_boundary(svm, X_moon_scaled, y_moon, axes[1], \"SVM (Linear, C=0.1)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28261466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflection\n",
    "# 1. Decision trees are axis-aligned because they split on one feature at a time.\n",
    "# 2. SVMs perform better when the boundary is curved and data is not separable linearly.\n",
    "# 3. Noise affects trees more due to overfitting, while SVMs can control flexibility with kernel + regularization."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
