{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2170fe2a",
   "metadata": {},
   "source": [
    "# ðŸ§  Decision Tree vs. SVM: A Practical Comparison\n",
    "This notebook will help you:\n",
    "- Understand decision boundaries\n",
    "- Experiment with model complexity\n",
    "- Evaluate model accuracy\n",
    "- Reflect on interpretability and generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f219c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris, make_moons, make_circles, make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, X, y, ax, title):\n",
    "    cmap_light = ListedColormap(['#FFBBBB', '#BBBBFF'])\n",
    "    cmap_bold = ['#FF0000', '#0000FF']\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap=cmap_light, alpha=0.7)\n",
    "    for i, color in zip(np.unique(y), cmap_bold):\n",
    "        ax.scatter(X[y == i, 0], X[y == i, 1], c=color, edgecolor='k', label=f\"Class {i}\", s=40)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a309c09",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 5: Evaluate Model Performance\n",
    "Now letâ€™s evaluate and compare both models on the same dataset using accuracy and classification report.\n",
    "**Task:** Evaluate both classifiers on `make_moons` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree = tree_moon.predict(X_moon_scaled)\n",
    "y_pred_svm = svm_moon.predict(X_moon_scaled)\n",
    "print(\"Tree Accuracy:\", accuracy_score(y_moon, y_pred_tree))\n",
    "print(classification_report(y_moon, y_pred_tree))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_moon, y_pred_svm))\n",
    "print(classification_report(y_moon, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d586404c",
   "metadata": {},
   "source": [
    "## ðŸ¤” Step 6: Reflection Questions\n",
    "Write your answers based on the experiments you've conducted.\n",
    "\n",
    "1. When did Decision Trees perform poorly, and why?\n",
    "2. How does changing `max_depth` affect overfitting or underfitting?\n",
    "3. What happens when `C` is too small or too large in SVM?\n",
    "4. Which model would you choose for a noisy, curved dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0226179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers to be written based on interpretation of results"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
